{"cells":[{"cell_type":"markdown","source":["This file: Extract investment-related text from ccalll transcript\n","\n","Input: folder 0_ccall: conference call transcripts\n","\n","Output:\n","- 0_sentences.csv: transcript split into sentence level\n","- 0_investment_sentences.csv: sentences related to investment"],"metadata":{"id":"6qgPD0eTvx3R"},"id":"6qgPD0eTvx3R"},{"cell_type":"code","execution_count":13,"id":"3d105a7a","metadata":{"id":"3d105a7a","executionInfo":{"status":"ok","timestamp":1747862684248,"user_tz":-120,"elapsed":3,"user":{"displayName":"Yiyang Wu","userId":"14558260507896847088"}}},"outputs":[],"source":["import os\n","import pandas as pd\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","import re"]},{"cell_type":"markdown","source":["Notice: If you're using colab, run the following two cells"],"metadata":{"id":"RtuIomH9vdnz"},"id":"RtuIomH9vdnz"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XyjXCFQ4uG6z","executionInfo":{"status":"ok","timestamp":1747862551668,"user_tz":-120,"elapsed":973,"user":{"displayName":"Yiyang Wu","userId":"14558260507896847088"}},"outputId":"60a52072-1f9b-4d4f-81c6-235d8f0d7819"},"id":"XyjXCFQ4uG6z","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","source":["os.chdir('/content/drive/MyDrive/Colab Notebooks/acct4_ta_s1')"],"metadata":{"id":"MEjzTBtauiFQ","executionInfo":{"status":"ok","timestamp":1747862610845,"user_tz":-120,"elapsed":6,"user":{"displayName":"Yiyang Wu","userId":"14558260507896847088"}}},"id":"MEjzTBtauiFQ","execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["Split txt into sentence level"],"metadata":{"id":"2rCtiY2hvlBk"},"id":"2rCtiY2hvlBk"},{"cell_type":"code","execution_count":11,"id":"7e8b8cf7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7e8b8cf7","executionInfo":{"status":"ok","timestamp":1747862666219,"user_tz":-120,"elapsed":15286,"user":{"displayName":"Yiyang Wu","userId":"14558260507896847088"}},"outputId":"eab55ebc-1d70-4c79-9534-3b469af73b0c"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Created 23175 sentence entries from 49 files\n"]}],"source":["# Download the punkt tokenizer models if needed\n","nltk.download('punkt', quiet=True)\n","nltk.download('punkt_tab')\n","\n","# Get all txt files in the ccall folder\n","txt_files = [f for f in os.listdir('0_ccall') if f.endswith('.txt')]\n","\n","# Initialize a list to store all sentences\n","all_sentences = []\n","sentence_id = 0\n","\n","# Process each file\n","for file_name in txt_files:\n","    file_path = os.path.join('0_ccall', file_name)\n","\n","    # Read the file content\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        text = file.read()\n","\n","    # Extract date from row 7 (index 6)\n","    lines = text.split('\\n')\n","    datadate = lines[6] if len(lines) > 6 else \"\"\n","    datadate = datadate.strip()\n","    if datadate and \" / \" in datadate:\n","        datadate = datadate.split(\" / \")[0]\n","\n","    # Split the text into sentences\n","    sentences = sent_tokenize(text)\n","\n","    # Add each sentence to our list with its metadata\n","    for sentence in sentences:\n","        sentence_id += 1\n","        all_sentences.append({\n","            'file_name': file_name,\n","            'sentence_id': sentence_id,\n","            'datadate': datadate,\n","            'sentence': sentence\n","        })\n","\n","# Create a DataFrame\n","df = pd.DataFrame(all_sentences)\n","\n","# Drop rows where sentence_id is missing\n","df = df.dropna(subset=['sentence_id'])\n","\n","# Save as dta file\n","df.to_csv('0_sentences.csv', encoding='utf-8', index=False)\n","print(f\"Created {len(all_sentences)} sentence entries from {len(txt_files)} files\")"]},{"cell_type":"markdown","source":["Extract sentences related to investment"],"metadata":{"id":"kEWh3F33vvHQ"},"id":"kEWh3F33vvHQ"},{"cell_type":"code","execution_count":14,"id":"f3f66b7c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3f66b7c","executionInfo":{"status":"ok","timestamp":1747862688252,"user_tz":-120,"elapsed":1713,"user":{"displayName":"Yiyang Wu","userId":"14558260507896847088"}},"outputId":"a193c9aa-3ef4-4776-ad0f-d4f0f2fa8800"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1333 sentences related to investments\n"]}],"source":["# Filter the dataframe for sentences that mention investment-related terms\n","KEYWORDS = [\n","    r'\\binvest(?:s|ing|ed|ment|or)?\\b',\n","    r'\\bcapex\\b', r'\\bcapx\\b',\n","    r'\\bcapital (?:expenditure|spending)s?\\b',\n","    r'\\bR&D\\b', r'\\bresearch and development\\b',\n","    r'\\bexpenditures?\\b', r'\\bspending\\b', r'\\bbudget allocation\\b',\n","    r'\\bfinancial commitment\\b', r'\\bdollar commitment\\b',\n","    r'\\$[0-9]+ (?:million|billion)',\n","    r'\\bcash injection\\b', r'\\bfunds?\\b', r'\\binfrastructure\\b',\n","    r'\\bexpansion\\b', r'\\bbuild-?out\\b', r'\\bdevelopment funding\\b',\n","    r'\\bportfolio\\b', r'\\bstrategic investment\\b', r'\\blong-term investment\\b',\n","]\n","\n","PATTERN = re.compile(r'(?i)(?:' + '|'.join(KEYWORDS) + r')')\n","investment_df = df[df['sentence'].str.contains(PATTERN)]\n","\n","# Show the result\n","print(f\"Found {len(investment_df)} sentences related to investments\")\n","investment_df.to_csv('0_investment_sentences.csv', encoding='utf-8', index=False)"]}],"metadata":{"kernelspec":{"display_name":"textual_analysis","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}